{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Dataframes\n",
    "\n",
    "In this lesson we will continue working with pandas DataFrames, and explore some more complex DataFrame manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of values for names column.\n",
    "\n",
    "students = ['Sally', 'Jane', 'Suzie', 'Billy', 'Ada', 'John', 'Thomas',\n",
    "            'Marie', 'Albert', 'Richard', 'Isaac', 'Alan']\n",
    "\n",
    "# Randomly generate arrays of scores for each student for each subject.\n",
    "# Note that all the values need to have the same length here.\n",
    "\n",
    "math_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "english_grades = np.random.randint(low=60, high=100, size=len(students))\n",
    "reading_grades = np.random.randint(low=60, high=100, size=len(students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the DataFrame using the above lists and arrays.\n",
    "\n",
    "df = pd.DataFrame({'name': students,\n",
    "                   'math': math_grades,\n",
    "                   'english': english_grades,\n",
    "                   'reading': reading_grades,\n",
    "                   'classroom': np.random.choice(['A', 'B'], len(students))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Lists and Dictionaries\n",
    "\n",
    "There are several ways to create dataframes, we've already seen how we can create a dataframe from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys in the passed dictionary will be the column names, and the values are the data points that make up each column.\n",
    "\n",
    "We can also create dataframes from a 2d data structure, either a numpy array or a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "pd.DataFrame(array, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that we had to specify the names of the columns ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From PyDataset.\n",
    "\n",
    "In some of the exercises, you'll need to load several datasets using the `pydataset` library. (If you get an error when trying to run the import below, use `pip` to install the `pydataset` package.) When the instructions say to load a dataset from PyDataset, you will need to do the following:\n",
    "\n",
    "The following import is necessary to access PyDataset datasets:\n",
    "```python\n",
    "from pydataset import data\n",
    "```\n",
    "\n",
    "Running this code snippet will show you the valuable information doc on the dataset:\n",
    "```python\n",
    "data(df_string_name, show_doc=True)\n",
    "```\n",
    "\n",
    "Running this code snippet will load the dataset for use as a pandas DataFrame:\n",
    "```python\n",
    "df = data(df_string_name)\n",
    "```\n",
    "\n",
    "There are 757 available datasets using pydataset. Running the following code snippet in a cell will return a DataFrame with all of your options:\n",
    "```python\n",
    "data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and store it in the variable mpg.\n",
    "\n",
    "from pydataset import data\n",
    "mpg = data('mpg')\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the documentation for the dataset, and any pydata dataset, by setting show_doc to True. This outputs valuable context for your dataset.\n",
    "\n",
    "```python\n",
    "data('mpg', show_doc=True) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From SQL\n",
    "\n",
    "We can use the `read_sql` method to create a dataframe based on the results of a SQL query. To do this, we need to tell pandas how to connect to the database we are querying. The way we communicate this to pandas is with a specially formatted *connection string*.\n",
    "\n",
    "In addition, whenever we want to connect to a database from our python code (other programming languages are similar), we will need a **driver**, a bit of software that handles the details of the database connection.\n",
    "\n",
    "In order to connect to mysql, we'll install the `mysqlclient` and `pymysql` driver packages:\n",
    "\n",
    "`python -m pip install mysqlclient pymysql`\n",
    "\n",
    "Once those are installed, we can create the connection string. In general, database connection urls will have this format:\n",
    "\n",
    "```python\n",
    "protocol://[user[:password]@]hostname/[database_name]\n",
    "```\n",
    "\n",
    "Here's an example of what one would look like:\n",
    "\n",
    "```python\n",
    "mysql+pymysql://codeup:p@assw0rd@123.123.123.123/some_db\n",
    "```\n",
    "\n",
    "Another thing we need to consider is that we don't want to publish our database credentials to github, however, we will need access to these values in our code in order to create the connection string defined above.\n",
    "\n",
    "In order to accomplish this, we can define several variables in a file named `env.py` that contain the sensitive data, add `env.py` to our `.gitignore` file, and then import those values into another script. \n",
    "\n",
    "**Be 100% sure to add `env.py` to this specific repository's `.gitignore` file, even and especially, if you have already added `env.py` to your global .gitignore file. This will protect the env file for people who clone this project (like collaborators)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import host, user, password\n",
    "\n",
    "url = f'mysql+pymysql://{user}:{password}@{host}/employees'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this url is defined, we can use it with the `read_sql` function to have pandas treat the results of a SQL query as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('SELECT * FROM employees LIMIT 5 OFFSET 50', url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to have longer SQL queries that we want to read into python, and an example of how we might break a query into several lines is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    emp_no,\n",
    "    first_name,\n",
    "    last_name\n",
    "FROM employees\n",
    "WHERE gender = 'F'\n",
    "LIMIT 100\n",
    "'''\n",
    "\n",
    "employees = pd.read_sql(sql, url)\n",
    "employees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Don't add and commit files with passwords or other sensitive information in them to a git repository!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    t.title as title,\n",
    "    d.dept_name as dept_name\n",
    "FROM titles t\n",
    "JOIN dept_emp USING (emp_no)\n",
    "JOIN departments d USING (dept_no)\n",
    "LIMIT 100\n",
    "'''\n",
    "\n",
    "title_dept = pd.read_sql(query, url)\n",
    "title_dept.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises I\n",
    "\n",
    "Run `python -m pip install mysqlclient pymysql` from your terminal to install pymysql and the mysqlclient.\n",
    "\n",
    "Create a notebook or python script named `advanced_dataframes` to do your work in for these exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run `python -m pip install mysqlclient pymysql` from your terminal to install the mysql client (any folder is fine)\n",
    "1. cd into your exercises folder for this module and run `echo env.py >> .gitignore`\n",
    "1. Create a function named `get_db_url`. It should accept a username, hostname, password, and database name and return a url connection string formatted like in the example at the start of this lesson.\n",
    "1. Use your function to obtain a connection to the `employees` database.\n",
    "1. Once you have successfully run a query:\n",
    "    - Intentionally make a typo in the database url. What kind of error message do you see?\n",
    "    - Intentionally make an error in your SQL query. What does the error message look like?\n",
    "6. Read the `employees` and `titles` tables into two separate DataFrames.\n",
    "7. How many rows and columns do you have in each DataFrame? Is that what you expected?\n",
    "8. Display the summary statistics for each DataFrame.\n",
    "9. How many unique titles are in the `titles` DataFrame?\n",
    "10. What is the oldest date in the `to_date` column? \n",
    "11. What is the most recent date in the `to_date` column?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
